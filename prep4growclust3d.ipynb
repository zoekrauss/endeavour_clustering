{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5219c4b5-83ce-4523-9f25-23f1cb632ce9",
   "metadata": {},
   "source": [
    "## Setting up data and control files for GrowClust3D\n",
    "Following: https://github.com/dttrugman/GrowClust3D/wiki/Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "748226e4-96a1-4a9e-ba35-dfb866433ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import obspy\n",
    "import glob2 as glob\n",
    "from obspy.clients.fdsn import Client\n",
    "from collections import defaultdict\n",
    "import pyarrow\n",
    "import itertools\n",
    "import obspy.signal.cross_correlation\n",
    "import dask\n",
    "client = Client('IRIS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056ae5b3-71d6-4001-b8fb-ecf57e2a0b5b",
   "metadata": {},
   "source": [
    "## Read in event information from QuakeML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d7e6bc69-08d4-4431-bec7-d170d8fa98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original events\n",
    "file = 'endquakes_2017.xml'\n",
    "cat = obspy.core.event.read_events(file)\n",
    "\n",
    "# FILTER IF SO DESIRED\n",
    "cat = cat.filter(\"time > 2017-09-01\",\"time < 2017-09-30\",\"longitude > -129.15\",\"longitude < -129.05\",\"latitude < 48.05\",\"latitude > 47.9\")\n",
    "\n",
    "origins = [p.origins[0] for p in cat.events]\n",
    "mags = np.empty(len(cat))\n",
    "for i,ev in enumerate(cat.events):\n",
    "    if len(ev.magnitudes)>0:\n",
    "        mags[i] = float(ev.magnitudes[0].mag)\n",
    "years = [p.time.year for p in origins]\n",
    "months = [p.time.month for p in origins]\n",
    "days = [p.time.day for p in origins]\n",
    "hours = [p.time.hour for p in origins]\n",
    "mins = [p.time.minute for p in origins]\n",
    "secs = [p.time.second + p.time.microsecond/1000000 for p in origins]\n",
    "lats = [p.latitude for p in origins]\n",
    "lons = [p.longitude for p in origins]\n",
    "depths = [p.depth for p in origins]\n",
    "arrivals = [len(p.arrivals) for p in origins]\n",
    "origin_ids = [str(p.resource_id)[-6:] for p in cat]\n",
    "erh = [float(p.origin_uncertainty.horizontal_uncertainty) for p in origins]\n",
    "erz = [float(p.depth_errors['uncertainty']) for p in origins]\n",
    "rms = np.zeros(len(cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffd3d7e-e15c-4d03-91e7-3751237fff72",
   "metadata": {},
   "source": [
    "## Make event text file\n",
    "\n",
    "yr mon day hr min sec lat lon dep mag errh errz rms evid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "69a06c7d-7ac2-45f7-b3b5-e93d640e3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "evtext_dict = {'yr':years,'mon':months,'day':days,'hr':hours,'min':mins,'sec':secs,'lat':lats,'lon':lons,'dep':depths,'mag':mags,'errh':erh,'errz':erz,'rms':rms,'evid':origin_ids}\n",
    "events = pd.DataFrame.from_dict(evtext_dict)\n",
    "events.to_csv('end_evlist.txt',sep='\\t',header=False,index=False,float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f15ebf-d949-4d85-bb39-7d23d1cdd8e5",
   "metadata": {},
   "source": [
    "## Make cross correlation text file by reading in the waveforms in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93426e90-c8e9-42c9-86f6-25f20bc79e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P: 0.3 s before, 0.5 s after\n",
    "# S: 0.3 s before, 1 s after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c9f16f3b-e17f-484c-80e7-83e530dfe5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up looping, so that we get all possible pairs of events but NO repeats!\n",
    "loop_ind = list(itertools.combinations(range(len(cat)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "350d98f9-4de2-46df-a926-742ca95224e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use the test example--\n",
    "\n",
    "id1 = 520320 # index 55 in catalog\n",
    "id2 = 520323 # index 56 in catalog\n",
    "loop_ind = [(55,56)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3eff98db-e811-4ecb-ab5c-1d362244dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_corr(phase,sta,chan,t1,t2,ot1,ot2):\n",
    "    \"\"\"\n",
    "    Cross correlates two phase picks from the same channel and calculates their differential travel times\n",
    "    This function pulls in the waveform data directly from Iris\n",
    "    \n",
    "    INPUT:\n",
    "    phase: 'P' or 'S'; this determines the size of the window cut around the pick time\n",
    "    sta: string, station code \n",
    "    chan: string, channel code\n",
    "    t1: pick time of first pick as UTCDatetime\n",
    "    t2: pick time of second pick as UTCDatetime\n",
    "    ot1: origin time of the earthquake the first pick is for in UTCDatetime\n",
    "    ot2: origin time of the earthquake the second pick is for in UTCDatetime\n",
    "    \n",
    "    RETURNS:\n",
    "    value: maximum cross correlation value of the waveform cut around the two picks\n",
    "    dtt: differential travel times of the two picks\n",
    "    \"\"\"\n",
    "    \n",
    "    if phase=='P':\n",
    "        t_off=[-0.3,0.5]\n",
    "        t_off=[-1,1.5]\n",
    "    if phase=='S':\n",
    "        t_off = [-1,2.5]\n",
    "        \n",
    "    # Pull in waveforms cut around picks\n",
    "    tr1 = client.get_waveforms('NV',sta,'',chan,t1+t_off[0],t1+t_off[1])\n",
    "    tr2 = client.get_waveforms('NV',sta,'',chan,t2+t_off[0],t2+t_off[1])\n",
    "    tr1.filter('bandpass',freqmin=5,freqmax=15)\n",
    "    tr2.filter('bandpass',freqmin=5,freqmax=15)\n",
    "    tr1.plot\n",
    "    tr2.plot\n",
    "    \n",
    "    # Cross correlate waveforms, allowing them to shift relative to each other for the case of faulty picks\n",
    "    xcor = obspy.signal.cross_correlation.correlate(tr1[0],tr2[0],100)\n",
    "    shift,value = obspy.signal.cross_correlation.xcorr_max(xcor)\n",
    "    \n",
    "    # Differential travel times, calculated as tt1-tt2\n",
    "    dtt = (t1-ot1) - (t2-ot2)\n",
    "    \n",
    "    return(value,dtt)\n",
    "\n",
    "\n",
    "def event_corr(pair):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    A tuple of indices of events in the catalog\n",
    "    \n",
    "    For the two events corresponding to those indices, finds the common picks between them and calculates\n",
    "    their cross correlation coefficient and differential travel times\n",
    "    \n",
    "    RETURNS:\n",
    "    A numpy array designed to be easily written to a text file in the format needed for GrowClust\n",
    "    Array has format ((ev1id,ev2id),(commonpick1,commonpick2,...))\n",
    "    Where each commonpick array has the format (station,differential travel time,cross correlation coefficient,phase)\n",
    "    \"\"\"\n",
    "    \n",
    "    path = 'sep2017_mseed/'\n",
    "    \n",
    "    i = pair[0]\n",
    "    j = pair[1]\n",
    "\n",
    "    ot1 = cat[i].origins[0].time\n",
    "    ot2 = cat[j].origins[0].time\n",
    "    sta1 = [p.waveform_id.station_code for p in cat[i].picks]\n",
    "    sta2 = [p.waveform_id.station_code for p in cat[j].picks]\n",
    "    pha1 = [a.phase for a in origins[i].arrivals]\n",
    "    pha2 = [a.phase for a in origins[j].arrivals]\n",
    "    picks1 = [a+'_'+pha1[k] for k,a in enumerate(sta1)]\n",
    "    picks2 = [a+'_'+pha2[k] for k,a in enumerate(sta2)]\n",
    "    common_picks = list(set(picks1).intersection(set(picks2)))\n",
    "\n",
    "    pick_arr = np.empty((len(common_picks),4),dtype=object)\n",
    "    for k,p in enumerate(common_picks):\n",
    "        # Find corresponding pick info within each event\n",
    "        # Send to pick_corr to get information\n",
    "        sta,phase = p.split('_')\n",
    "\n",
    "        sta1_ind = [ ind for ind in range(len(sta1)) if sta1[ind] == sta ]\n",
    "        pha1_ind = [ ind for ind in range(len(pha1)) if pha1[ind] == phase ]\n",
    "        pick1_ind = list(set(sta1_ind).intersection(set(pha1_ind)))\n",
    "        pick1 = cat[i].picks[pick1_ind[0]]\n",
    "\n",
    "        sta2_ind = [ ind for ind in range(len(sta2)) if sta2[ind] == sta ]\n",
    "        pha2_ind = [ ind for ind in range(len(pha2)) if pha2[ind] == phase ]\n",
    "        pick2_ind = list(set(sta2_ind).intersection(set(pha2_ind)))\n",
    "        pick2 = cat[j].picks[pick2_ind[0]]\n",
    "\n",
    "        chan = pick1.waveform_id.channel_code\n",
    "        xcor_val,dtt = pick_corr_mseed(phase,sta,chan,origin_ids[i],origin_ids[j],pick1.time,pick2.time,ot1,ot2,path)\n",
    "        # xcor_val,dtt = pick_corr(phase,sta,chan,pick1.time,pick2.time,ot1,ot2)\n",
    "\n",
    "        # Write station- and phase-specific line\n",
    "        \n",
    "        pick_arr[k][0]=sta\n",
    "        pick_arr[k][1]=dtt\n",
    "        pick_arr[k][2]=xcor_val\n",
    "        pick_arr[k][3] = phase\n",
    "        \n",
    "    \n",
    "    return(((origin_ids[i],origin_ids[j]),pick_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3f01ef53-bc84-4762-b1f9-ee8d837b1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_corr_mseed(phase,sta,chan,evid1,evid2,t1,t2,ot1,ot2,path):\n",
    "    \"\"\"\n",
    "    Cross correlates two phase picks from the same channel and calculates their differential travel times\n",
    "    This function reads waveform data from local miniseed files\n",
    "    \n",
    "    INPUT:\n",
    "    phase: 'P' or 'S'; this determines the size of the window cut around the pick time\n",
    "    sta: string, station code \n",
    "    chan: string, channel code\n",
    "    t1: pick time of first pick as UTCDatetime\n",
    "    t2: pick time of second pick as UTCDatetime\n",
    "    ot1: origin time of the earthquake the first pick is for in UTCDatetime\n",
    "    ot2: origin time of the earthquake the second pick is for in UTCDatetime\n",
    "    path: path to the folder that stores the mseed files, as a string. eg 'sep2017_mseed/'\n",
    "    \n",
    "    RETURNS:\n",
    "    value: maximum cross correlation value of the waveform cut around the two picks\n",
    "    dtt: differential travel times of the two picks\n",
    "    \"\"\"\n",
    "    \n",
    "    if phase=='P':\n",
    "        t_off=[-0.2,0.6]\n",
    "        # t_off=[-1,1.5]\n",
    "    if phase=='S':\n",
    "        t_off = [-0.3,0.6]\n",
    "\n",
    "    # Pull in waveforms\n",
    "    fid1 = path+str(evid1)+'.mseed'\n",
    "    fid2 = path+str(evid2)+'.mseed'\n",
    "    tr1 = obspy.read(fid1).select(station=sta,channel=chan).detrend()\n",
    "    tr2 = obspy.read(fid2).select(station=sta,channel=chan).detrend()\n",
    "    \n",
    "    # Filter\n",
    "    tr1.filter('bandpass',freqmin=8,freqmax=35)\n",
    "    tr2.filter('bandpass',freqmin=8,freqmax=35)\n",
    "    \n",
    "    # Cut the waveforms around picks\n",
    "    tr1.trim(starttime=t1+t_off[0],endtime=t1+t_off[1])\n",
    "    tr2.trim(starttime=t2+t_off[0],endtime=t2+t_off[1])\n",
    "    \n",
    "    \n",
    "    # Cross correlate waveforms, allowing them to shift relative to each other for the case of faulty picks\n",
    "    xcor = obspy.signal.cross_correlation.correlate(tr1[0],tr2[0],100)\n",
    "    shift,value = obspy.signal.cross_correlation.xcorr_max(xcor)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Differential travel times, calculated using the shift\n",
    "    new_t2 = t2-(shift/tr2[0].stats.sampling_rate)\n",
    "    dtt = (t1-ot1) - (new_t2-ot2)\n",
    "    \n",
    "    return(value,dtt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3034fc64-5d42-4076-a5fb-e153d501e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def loop_pairs(pair):\n",
    "    try:\n",
    "        test = event_corr(pair)\n",
    "        return test\n",
    "    except: \n",
    "        print(pair)\n",
    "\n",
    "\n",
    "lazy_results = [loop_pairs(pair) for pair in loop_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "29869eee-4efe-4ad3-8628-dc15ca716a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 37s, sys: 2min 54s, total: 11min 31s\n",
      "Wall time: 8min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = dask.compute(lazy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6942755a-64b7-4619-a4a0-e257820a17e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n",
      "ENWF\n",
      "HHE\n",
      "6 Trace(s) in Stream:\n",
      "NV.ENWF..HHE | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.ENWF..HHZ | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.KEMO..EHE | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.KEMO..EHZ | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.NCHR..EHE | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.NCHR..EHZ | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "6 Trace(s) in Stream:\n",
      "NV.ENWF..HHE | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.ENWF..HHZ | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.KEMO..EHE | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.KEMO..EHZ | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.NCHR..EHE | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.NCHR..EHZ | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "1 Trace(s) in Stream:\n",
      "NV.ENWF..HHE | 2017-09-03T17:20:09.930000Z - 2017-09-03T17:20:10.830000Z | 200.0 Hz, 181 samples\n",
      "1 Trace(s) in Stream:\n",
      "NV.ENWF..HHE | 2017-09-29T18:37:22.850000Z - 2017-09-29T18:37:23.750000Z | 200.0 Hz, 181 samples\n",
      "S\n",
      "NCHR\n",
      "EHE\n",
      "6 Trace(s) in Stream:\n",
      "NV.ENWF..HHE | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.ENWF..HHZ | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.KEMO..EHE | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.KEMO..EHZ | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.NCHR..EHE | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.NCHR..EHZ | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "6 Trace(s) in Stream:\n",
      "NV.ENWF..HHE | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.ENWF..HHZ | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.KEMO..EHE | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.KEMO..EHZ | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.NCHR..EHE | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.NCHR..EHZ | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "1 Trace(s) in Stream:\n",
      "NV.NCHR..EHE | 2017-09-03T17:20:09.750000Z - 2017-09-03T17:20:10.650000Z | 200.0 Hz, 181 samples\n",
      "1 Trace(s) in Stream:\n",
      "NV.NCHR..EHE | 2017-09-29T18:37:22.465000Z - 2017-09-29T18:37:23.365000Z | 200.0 Hz, 181 samples\n",
      "S\n",
      "KEMO\n",
      "EHE\n",
      "6 Trace(s) in Stream:\n",
      "NV.ENWF..HHE | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.ENWF..HHZ | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.KEMO..EHE | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.KEMO..EHZ | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.NCHR..EHE | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.NCHR..EHZ | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "6 Trace(s) in Stream:\n",
      "NV.ENWF..HHE | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.ENWF..HHZ | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.KEMO..EHE | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.KEMO..EHZ | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.NCHR..EHE | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.NCHR..EHZ | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "1 Trace(s) in Stream:\n",
      "NV.KEMO..EHE | 2017-09-03T17:20:10.940000Z - 2017-09-03T17:20:11.840000Z | 200.0 Hz, 181 samples\n",
      "1 Trace(s) in Stream:\n",
      "NV.KEMO..EHE | 2017-09-29T18:37:22.100000Z - 2017-09-29T18:37:23.000000Z | 200.0 Hz, 181 samples\n",
      "S\n",
      "KEMF\n",
      "EHE\n",
      "6 Trace(s) in Stream:\n",
      "NV.ENWF..HHE | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.ENWF..HHZ | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.KEMO..EHE | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.KEMO..EHZ | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.NCHR..EHE | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "NV.NCHR..EHZ | 2017-09-03T17:20:05.050000Z - 2017-09-03T17:20:16.240000Z | 200.0 Hz, 2239 samples\n",
      "6 Trace(s) in Stream:\n",
      "NV.ENWF..HHE | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.ENWF..HHZ | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.KEMO..EHE | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.KEMO..EHZ | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.NCHR..EHE | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "NV.NCHR..EHZ | 2017-09-29T18:37:16.640000Z - 2017-09-29T18:37:28.150000Z | 200.0 Hz, 2303 samples\n",
      "0 Trace(s) in Stream:\n",
      "\n",
      "0 Trace(s) in Stream:\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [169]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevent_corr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m58\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m506\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [142]\u001b[0m, in \u001b[0;36mevent_corr\u001b[0;34m(pair)\u001b[0m\n\u001b[1;32m     87\u001b[0m pick2 \u001b[38;5;241m=\u001b[39m cat[j]\u001b[38;5;241m.\u001b[39mpicks[pick2_ind[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m     89\u001b[0m chan \u001b[38;5;241m=\u001b[39m pick1\u001b[38;5;241m.\u001b[39mwaveform_id\u001b[38;5;241m.\u001b[39mchannel_code\n\u001b[0;32m---> 90\u001b[0m xcor_val,dtt \u001b[38;5;241m=\u001b[39m \u001b[43mpick_corr_mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\u001b[43msta\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchan\u001b[49m\u001b[43m,\u001b[49m\u001b[43morigin_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43morigin_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpick1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpick2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43mot1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mot2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# xcor_val,dtt = pick_corr(phase,sta,chan,pick1.time,pick2.time,ot1,ot2)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Write station- and phase-specific line\u001b[39;00m\n\u001b[1;32m     95\u001b[0m pick_arr[k][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m=\u001b[39msta\n",
      "Input \u001b[0;32mIn [168]\u001b[0m, in \u001b[0;36mpick_corr_mseed\u001b[0;34m(phase, sta, chan, evid1, evid2, t1, t2, ot1, ot2, path)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(tr1)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(tr2)\n\u001b[0;32m---> 50\u001b[0m xcor \u001b[38;5;241m=\u001b[39m obspy\u001b[38;5;241m.\u001b[39msignal\u001b[38;5;241m.\u001b[39mcross_correlation\u001b[38;5;241m.\u001b[39mcorrelate(\u001b[43mtr1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m,tr2[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     51\u001b[0m shift,value \u001b[38;5;241m=\u001b[39m obspy\u001b[38;5;241m.\u001b[39msignal\u001b[38;5;241m.\u001b[39mcross_correlation\u001b[38;5;241m.\u001b[39mxcorr_max(xcor)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Differential travel times, calculated using the shift\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/alaska-ml/lib/python3.9/site-packages/obspy/core/stream.py:643\u001b[0m, in \u001b[0;36mStream.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(traces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraces\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(index))\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "event_corr((58,506))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3068cdfb-4f4b-45ef-be7b-026fc6e7fd00",
   "metadata": {},
   "source": [
    "## Write to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "251c4678-108b-4cc5-bce8-2f80e450fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('end_xcordata_0835_1.txt','w') as fl:\n",
    "    \n",
    "    for arr in results[0]:\n",
    "        \n",
    "        # Write event pair ID line\n",
    "        fl.write('#'+'\\t'+arr[0][0]+'\\t'+arr[0][1]+'\\t'+'0.000')\n",
    "        fl.write('\\n')\n",
    "        \n",
    "        for pick in arr[1]:\n",
    "            # Write station- and phase-specific line\n",
    "            fl.write(pick[0]+'\\t'+'{:.4f}'.format(pick[1])+'\\t'+'{:.4f}'.format(pick[2])+'\\t'+pick[3])\n",
    "            fl.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b9b7b-b2c1-4e7f-aee3-823f59dcff28",
   "metadata": {},
   "source": [
    "## Read in event waveforms to store and then cross-correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d6cac192-9fd0-4070-800c-a9ce3b1ad62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in cat:\n",
    "    \n",
    "    evid = str(event.resource_id)[-6:]\n",
    "    \n",
    "    t1 = min([p.time for p in event.picks])-5\n",
    "    t2 = max([p.time for p in event.picks])+5\n",
    "    \n",
    "    sta = \",\".join(np.unique([p.waveform_id.station_code for p in event.picks]))\n",
    "    chan = \",\".join(np.unique([p.waveform_id.channel_code for p in event.picks]))\n",
    "    \n",
    "    st = client.get_waveforms('NV',sta,'',chan,t1,t2)\n",
    "\n",
    "    st.write('sep2017_mseed/'+str(evid)+'.mseed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e40b4-c23d-4c2d-973b-93939197215c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alaska-ml",
   "language": "python",
   "name": "alaska-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
