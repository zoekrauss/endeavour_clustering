{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5219c4b5-83ce-4523-9f25-23f1cb632ce9",
   "metadata": {},
   "source": [
    "## Setting up data and control files for GrowClust3D\n",
    "Following: https://github.com/dttrugman/GrowClust3D/wiki/Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "748226e4-96a1-4a9e-ba35-dfb866433ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import obspy\n",
    "import glob2 as glob\n",
    "from obspy.clients.fdsn import Client\n",
    "from collections import defaultdict\n",
    "import pyarrow\n",
    "import itertools\n",
    "import obspy.signal.cross_correlation\n",
    "import dask\n",
    "client = Client('IRIS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056ae5b3-71d6-4001-b8fb-ecf57e2a0b5b",
   "metadata": {},
   "source": [
    "## Read in event information from QuakeML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e6bc69-08d4-4431-bec7-d170d8fa98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original events\n",
    "file = 'endquakes_2017.xml'\n",
    "cat = obspy.core.event.read_events(file)\n",
    "\n",
    "# FILTER IF SO DESIRED\n",
    "#cat = cat.filter(\"time < 2017-01-02\")\n",
    "\n",
    "origins = [p.origins[0] for p in cat.events]\n",
    "mags = np.empty(len(cat))\n",
    "for i,ev in enumerate(cat.events):\n",
    "    if len(ev.magnitudes)>0:\n",
    "        mags[i] = float(ev.magnitudes[0].mag)\n",
    "years = [p.time.year for p in origins]\n",
    "months = [p.time.month for p in origins]\n",
    "days = [p.time.day for p in origins]\n",
    "hours = [p.time.hour for p in origins]\n",
    "mins = [p.time.minute for p in origins]\n",
    "secs = [p.time.second + p.time.microsecond/1000000 for p in origins]\n",
    "lats = [p.latitude for p in origins]\n",
    "lons = [p.longitude for p in origins]\n",
    "depths = [p.depth for p in origins]\n",
    "arrivals = [len(p.arrivals) for p in origins]\n",
    "origin_ids = [str(p.resource_id)[-6:] for p in cat]\n",
    "erh = [float(p.origin_uncertainty.horizontal_uncertainty) for p in origins]\n",
    "erz = [float(p.depth_errors['uncertainty']) for p in origins]\n",
    "rms = np.zeros(len(cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffd3d7e-e15c-4d03-91e7-3751237fff72",
   "metadata": {},
   "source": [
    "## Make event text file\n",
    "\n",
    "yr mon day hr min sec lat lon dep mag errh errz rms evid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "69a06c7d-7ac2-45f7-b3b5-e93d640e3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "evtext_dict = {'yr':years,'mon':months,'day':days,'hr':hours,'min':mins,'sec':secs,'lat':lats,'lon':lons,'dep':depths,'mag':mags,'errh':erh,'errz':erz,'rms':rms,'evid':origin_ids}\n",
    "events = pd.DataFrame.from_dict(evtext_dict)\n",
    "events.to_csv('end_evlist.txt',sep='\\t',header=False,index=False,float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f15ebf-d949-4d85-bb39-7d23d1cdd8e5",
   "metadata": {},
   "source": [
    "## Make cross correlation text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93426e90-c8e9-42c9-86f6-25f20bc79e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P: 0.3 s before, 0.5 s after\n",
    "# S: 0.3 s before, 1 s after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f16f3b-e17f-484c-80e7-83e530dfe5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up looping, so that we get all possible pairs of events but NO repeats!\n",
    "loop_ind = list(itertools.combinations(range(len(cat)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3eff98db-e811-4ecb-ab5c-1d362244dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_corr(phase,sta,chan,t1,t2,ot1,ot2):\n",
    "    \"\"\"\n",
    "    Cross correlates two phase picks from the same channel and calculates their differential travel times\n",
    "    \n",
    "    INPUT:\n",
    "    phase: 'P' or 'S'; this determines the size of the window cut around the pick time\n",
    "    sta: string, station code \n",
    "    chan: string, channel code\n",
    "    t1: pick time of first pick as UTCDatetime\n",
    "    t2: pick time of second pick as UTCDatetime\n",
    "    ot1: origin time of the earthquake the first pick is for in UTCDatetime\n",
    "    ot2: origin time of the earthquake the second pick is for in UTCDatetime\n",
    "    \n",
    "    RETURNS:\n",
    "    value: maximum cross correlation value of the waveform cut around the two picks\n",
    "    dtt: differential travel times of the two picks\n",
    "    \"\"\"\n",
    "    \n",
    "    if phase=='P':\n",
    "        t_off=[-0.3,0.5]\n",
    "        t_off=[-1,1.5]\n",
    "    if phase=='S':\n",
    "        t_off = [-1,2.5]\n",
    "        \n",
    "    # Pull in waveforms cut around picks\n",
    "    tr1 = client.get_waveforms('NV',sta,'',chan,t1-t_off[0],t1+t_off[1])\n",
    "    tr2 = client.get_waveforms('NV',sta,'',chan,t2-t_off[0],t2+t_off[1])\n",
    "    tr1.filter('bandpass',freqmin=5,freqmax=15)\n",
    "    tr2.filter('bandpass',freqmin=5,freqmax=15)\n",
    "    tr1.plot\n",
    "    tr2.plot\n",
    "    \n",
    "    # Cross correlate waveforms, allowing them to shift relative to each other for the case of faulty picks\n",
    "    xcor = obspy.signal.cross_correlation.correlate(tr1[0],tr2[0],100)\n",
    "    shift,value = obspy.signal.cross_correlation.xcorr_max(xcor)\n",
    "    \n",
    "    # Differential travel times, calculated as tt1-tt2\n",
    "    dtt = (t1-ot1) - (t2-ot2)\n",
    "    \n",
    "    return(value,dtt)\n",
    "\n",
    "\n",
    "def event_corr(pair):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    A tuple of indices of events in the catalog\n",
    "    \n",
    "    For the two events corresponding to those indices, finds the common picks between them and calculates\n",
    "    their cross correlation coefficient and differential travel times\n",
    "    \n",
    "    RETURNS:\n",
    "    A numpy array designed to be easily written to a text file in the format needed for GrowClust\n",
    "    Array has format ((ev1id,ev2id),(commonpick1,commonpick2,...))\n",
    "    Where each commonpick array has the format (station,differential travel time,cross correlation coefficient,phase)\n",
    "    \"\"\"\n",
    "    \n",
    "    i = pair[0]\n",
    "    j = pair[1]\n",
    "\n",
    "    ot1 = cat[i].origins[0].time\n",
    "    ot2 = cat[j].origins[0].time\n",
    "    sta1 = [p.waveform_id.station_code for p in cat[i].picks]\n",
    "    sta2 = [p.waveform_id.station_code for p in cat[j].picks]\n",
    "    pha1 = [a.phase for a in origins[i].arrivals]\n",
    "    pha2 = [a.phase for a in origins[j].arrivals]\n",
    "    picks1 = [a+'_'+pha1[k] for k,a in enumerate(sta1)]\n",
    "    picks2 = [a+'_'+pha2[k] for k,a in enumerate(sta2)]\n",
    "    common_picks = list(set(picks1).intersection(set(picks2)))\n",
    "\n",
    "    pick_arr = np.empty((len(common_picks),4),dtype=object)\n",
    "    for k,p in enumerate(common_picks):\n",
    "        # Find corresponding pick info within each event\n",
    "        # Send to pick_corr to get information\n",
    "        sta,phase = p.split('_')\n",
    "\n",
    "        sta1_ind = [ ind for ind in range(len(sta1)) if sta1[ind] == sta ]\n",
    "        pha1_ind = [ ind for ind in range(len(pha1)) if pha1[ind] == phase ]\n",
    "        pick1_ind = list(set(sta1_ind).intersection(set(pha1_ind)))\n",
    "        pick1 = cat[i].picks[pick1_ind[0]]\n",
    "\n",
    "        sta2_ind = [ ind for ind in range(len(sta2)) if sta2[ind] == sta ]\n",
    "        pha2_ind = [ ind for ind in range(len(pha2)) if pha2[ind] == phase ]\n",
    "        pick2_ind = list(set(sta2_ind).intersection(set(pha2_ind)))\n",
    "        pick2 = cat[j].picks[pick2_ind[0]]\n",
    "\n",
    "        chan = pick1.waveform_id.channel_code\n",
    "        xcor_val,dtt = pick_corr(phase,sta,chan,pick1.time,pick2.time,ot1,ot2)\n",
    "\n",
    "        # Write station- and phase-specific line\n",
    "        \n",
    "        pick_arr[k][0]=sta\n",
    "        pick_arr[k][1]=dtt\n",
    "        pick_arr[k][2]=xcor_val\n",
    "        pick_arr[k][3] = phase\n",
    "        \n",
    "    \n",
    "    return(((origin_ids[i],origin_ids[j]),pick_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3034fc64-5d42-4076-a5fb-e153d501e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def loop_pairs(pair):\n",
    "    return event_corr(pair)\n",
    "\n",
    "\n",
    "lazy_results = [loop_pairs(pair) for pair in loop_ind[0:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29869eee-4efe-4ad3-8628-dc15ca716a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 204 ms, sys: 27.2 ms, total: 231 ms\n",
      "Wall time: 6.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = dask.compute(lazy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3068cdfb-4f4b-45ef-be7b-026fc6e7fd00",
   "metadata": {},
   "source": [
    "## Write to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "251c4678-108b-4cc5-bce8-2f80e450fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('end_xcordata.txt','w') as fl:\n",
    "    \n",
    "    for arr in results[0]:\n",
    "        \n",
    "        # Write event pair ID line\n",
    "        fl.write('#'+'\\t'+arr[0][0]+'\\t'+arr[0][1]+'\\t'+'0.000')\n",
    "        fl.write('\\n')\n",
    "        \n",
    "        for pick in arr[1]:\n",
    "            # Write station- and phase-specific line\n",
    "            fl.write(pick[0]+'\\t'+'{:.4f}'.format(pick[1])+'\\t'+'{:.4f}'.format(pick[2])+'\\t'+pick[3])\n",
    "            fl.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f724c4-72f8-4c53-8f98-f5b05492e116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alaska-ml",
   "language": "python",
   "name": "alaska-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
